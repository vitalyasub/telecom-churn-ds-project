# ===============================================================
# –ü—Ä–æ–≥–Ω–æ–∑ –í—ñ–¥—Ç–æ–∫—É –ö–ª—ñ—î–Ω—Ç—ñ–≤ ‚Äî Streamlit App
# ===============================================================
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import os
import time
import warnings
from typing import Tuple, Any
from math import pi
from datetime import datetime

# ---------------------------------------------------------------
# 1. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏
# ---------------------------------------------------------------
st.set_page_config(
    page_title="–ü—Ä–æ–≥–Ω–æ–∑ –í—ñ–¥—Ç–æ–∫—É –ö–ª—ñ—î–Ω—Ç—ñ–≤",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded",
)
warnings.filterwarnings("ignore", message="Glyph.*missing from font")

plt.rcParams["font.family"] = "DejaVu Sans"
plt.style.use("ggplot")

# ---------------------------------------------------------------
# 2. –ö–∞—Å—Ç–æ–º–Ω—ñ –°—Ç–∏–ª—ñ CSS
# ---------------------------------------------------------------
st.markdown(
    """
<style>
    :root {
        --primary-dark: #324851;
        --primary-green: #86AC41;
        --secondary-teal: #34675C;
        --accent-light: #7DA3A1;
        --white: #ffffff;
        --error: #dc3545;
        --warning: #ffc107;
    }

    h1, h2, h3, h4, h5, h6 {
        color: var(--primary-dark) !important;
        font-weight: 700 !important;
    }

    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #324851 0%, #34675C 100%);
    }

    [data-testid="stSidebar"] * {
        color: var(--white) !important;
    }

    [data-testid="stSidebar"] .stRadio > div {
        background-color: rgba(255, 255, 255, 0.1);
        border-radius: 8px;
        padding: 0.5rem;
        transition: all 0.3s ease;
    }

    [data-testid="stSidebar"] .stRadio > div:hover {
        background-color: rgba(255, 255, 255, 0.2);
    }

    .stButton {
        display: flex !important;
        justify-content: center !important;
        margin: 2rem auto !important;
    }

    .stButton > button {
        background: linear-gradient(135deg, var(--primary-green) 0%, var(--secondary-teal) 100%);
        color: var(--white);
        border: none;
        border-radius: 10px;
        padding: 0.75rem 2rem;
        font-weight: 600;
        font-size: 16px;
        transition: all 0.3s ease;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }

    .stButton > button:hover {
        background: linear-gradient(135deg, var(--secondary-teal) 0%, var(--primary-green) 100%);
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2);
        transform: translateY(-2px);
    }

    .stDownloadButton > button {
        background: linear-gradient(135deg, var(--accent-light) 0%, var(--secondary-teal) 100%);
        color: var(--white);
        border: none;
        border-radius: 10px;
        padding: 0.75rem 1.5rem;
        font-weight: 600;
        transition: all 0.3s ease;
    }

    .stDownloadButton > button:hover {
        background: linear-gradient(135deg, var(--secondary-teal) 0%, var(--accent-light) 100%);
        transform: translateY(-2px);
    }

    [data-testid="stMetricValue"] {
        color: var(--primary-dark);
        font-size: 2rem !important;
        font-weight: 700 !important;
    }

    [data-testid="stMetricLabel"] {
        color: var(--secondary-teal);
        font-weight: 600 !important;
    }

    .stProgress > div > div > div {
        background: linear-gradient(90deg, var(--primary-green) 0%, var(--secondary-teal) 100%);
    }
</style>
""",
    unsafe_allow_html=True,
)

# ---------------------------------------------------------------
# 3. –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏
# ---------------------------------------------------------------
FEATURE_NAMES_MAP = {
    "reamining_contract": "–ó–∞–ª–∏—à–æ–∫ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É",
    "subscription_age": "–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –ø—ñ–¥–ø–∏—Å–∫–∏",
    "service_failure_count": "–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–±–æ—ó–≤ —Å–µ—Ä–≤—ñ—Å—É",
    "bill_avg": "–°–µ—Ä–µ–¥–Ω—ñ–π —Ä–∞—Ö—É–Ω–æ–∫",
    "download_avg": "–°–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è",
    "upload_avg": "–°–µ—Ä–µ–¥–Ω—î –≤—ñ–¥–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è",
    "is_tv_subscriber": "–ü—ñ–¥–ø–∏—Å–∫–∞ –Ω–∞ –¢–ë",
    "is_movie_package_subscriber": "–ü–∞–∫–µ—Ç —Ñ—ñ–ª—å–º—ñ–≤",
    "download_over_limit": "–ü–µ—Ä–µ–≤–∏—â–µ–Ω–Ω—è –ª—ñ–º—ñ—Ç—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è",
}

FIELD_TOOLTIPS = {
    "subscription_age": "–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—ó –ø—ñ–¥–ø–∏—Å–∫–∏ –∫–ª—ñ—î–Ω—Ç–∞ —É —Ä–æ–∫–∞—Ö",
    "bill_avg": "–°–µ—Ä–µ–¥–Ω—å–æ–º—ñ—Å—è—á–Ω–∏–π —Ä–∞—Ö—É–Ω–æ–∫ –∫–ª—ñ—î–Ω—Ç–∞ –≤ –¥–æ–ª–∞—Ä–∞—Ö –°–®–ê",
    "reamining_contract": "–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–æ–∫—ñ–≤ –¥–æ –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É",
    "service_failure_count": "–ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö –∑–±–æ—ó–≤",
    "download_avg": "–°–µ—Ä–µ–¥–Ω—ñ–π –º—ñ—Å—è—á–Ω–∏–π –æ–±—Å—è–≥ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É –ì–ë",
    "upload_avg": "–°–µ—Ä–µ–¥–Ω—ñ–π –º—ñ—Å—è—á–Ω–∏–π –æ–±—Å—è–≥ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É –ì–ë",
}


# ---------------------------------------------------------------
# 4. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
# ---------------------------------------------------------------
@st.cache_resource
def load_model() -> Tuple[Any, Any]:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∑–±–µ—Ä–µ–∂–µ–Ω—É –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è (LightGBM) —Ç–∞ —Å–∫–µ–π–ª–µ—Ä (Scaler)
    –∑ —Ñ–∞–π–ª–æ–≤–æ—ó —Å–∏—Å—Ç–µ–º–∏.

    –¶—è —Ñ—É–Ω–∫—Ü—ñ—è –∫–µ—à—É—î—Ç—å—Å—è Streamlit'–æ–º, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è.

    Returns:
        Tuple[Any, Any]: –ö–æ—Ä—Ç–µ–∂, —â–æ –º—ñ—Å—Ç–∏—Ç—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—É –º–æ–¥–µ–ª—å —Ç–∞ —Å–∫–µ–π–ª–µ—Ä.
                         –ü–æ–≤–µ—Ä—Ç–∞—î (None, None) —É —Ä–∞–∑—ñ –ø–æ–º–∏–ª–∫–∏ –∞–±–æ –≤—ñ–¥—Å—É—Ç–Ω–æ—Å—Ç—ñ —Ñ–∞–π–ª—ñ–≤.
    """
    model_path = "models/best_model_LightGBM.pkl"
    scaler_path = "models/scaler.pkl"

    model, scaler = None, None
    if os.path.exists(model_path) and os.path.exists(scaler_path):
        try:
            model = joblib.load(model_path)
            scaler = joblib.load(scaler_path)
            st.success("‚úÖ –ú–æ–¥–µ–ª—å —Ç–∞ —Å–∫–µ–π–ª–µ—Ä —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")
        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ: {e}")
    else:
        st.error(f"‚ùå –§–∞–π–ª–∏ –º–æ–¥–µ–ª—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ: {model_path}, {scaler_path}")

    return model, scaler


model, scaler = load_model()
MODEL_LOADED = model is not None and scaler is not None


# ---------------------------------------------------------------
# 5. –î–æ–ø–æ–º—ñ–∂–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
# ---------------------------------------------------------------
def align_features(input_df: pd.DataFrame, scaler: Any) -> pd.DataFrame:
    """
    –í–∏—Ä—ñ–≤–Ω—é—î —Å—Ç–æ–≤–ø—Ü—ñ –≤—Ö—ñ–¥–Ω–æ–≥–æ DataFrame –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ –¥–æ –æ—á—ñ–∫—É–≤–∞–Ω–∏—Ö –æ–∑–Ω–∞–∫
    —Å–∫–µ–π–ª–µ—Ä–∞ (–∞–±–æ –º–æ–¥–µ–ª—ñ) —ñ –∑–∞–ø–æ–≤–Ω—é—î –≤—ñ–¥—Å—É—Ç–Ω—ñ —Å—Ç–æ–≤–ø—Ü—ñ –Ω—É–ª—è–º–∏.

    –¶–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–æ –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ.

    Args:
        input_df (pd.DataFrame): –í—Ö—ñ–¥–Ω–∏–π DataFrame –∑ –¥–∞–Ω–∏–º–∏ –∫–ª—ñ—î–Ω—Ç–∞.
        scaler (Any): –û–±'—î–∫—Ç —Å–∫–µ–π–ª–µ—Ä–∞ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, StandardScaler) –∑ –∞—Ç—Ä–∏–±—É—Ç–æ–º
                      `feature_names_in_` –∞–±–æ —ñ–Ω—à–∏–º —Å–ø–æ—Å–æ–±–æ–º –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –æ—á—ñ–∫—É–≤–∞–Ω–∏—Ö –æ–∑–Ω–∞–∫.

    Returns:
        pd.DataFrame: DataFrame –∑ –≤–∏—Ä—ñ–≤–Ω—è–Ω–∏–º–∏ —Å—Ç–æ–≤–ø—Ü—è–º–∏.
    """
    expected = getattr(scaler, "feature_names_in_", None)
    if expected is not None:
        input_df = input_df.reindex(columns=expected, fill_value=0)
    return input_df


def prepare_input_data(
    is_tv, is_movie, sub_age, bill, contract, failures, down, up, over_limit
):
    """
    –§–æ—Ä–º—É—î DataFrame –∑ –æ–¥–Ω—ñ—î—ó —Å—Ç—Ä—ñ—á–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞.
    –í–∏–∫–æ–Ω—É—î –∫–æ–¥—É–≤–∞–Ω–Ω—è –±—ñ–Ω–∞—Ä–Ω–∏—Ö –æ–∑–Ω–∞–∫ ("–¢–∞–∫"/"–ù—ñ" –≤ 1/0).

    Args:
        is_tv (str): –ß–∏ —î –ø—ñ–¥–ø–∏—Å–∫–∞ –Ω–∞ –¢–ë ("–¢–∞–∫" –∞–±–æ "–ù—ñ").
        is_movie (str): –ß–∏ —î –ø–∞–∫–µ—Ç —Ñ—ñ–ª—å–º—ñ–≤ ("–¢–∞–∫" –∞–±–æ "–ù—ñ").
        sub_age (float): –¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –ø—ñ–¥–ø–∏—Å–∫–∏ (—Ä–æ–∫—ñ–≤).
        bill (float): –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–∞—Ö—É–Ω–æ–∫ ($).
        contract (float): –ó–∞–ª–∏—à–æ–∫ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É (—Ä–æ–∫—ñ–≤).
        failures (int): –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–±–æ—ó–≤ —Å–µ—Ä–≤—ñ—Å—É.
        down (float): –°–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (GB).
        up (float): –°–µ—Ä–µ–¥–Ω—î –≤—ñ–¥–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (GB).
        over_limit (str): –ß–∏ –±—É–ª–æ –ø–µ—Ä–µ–≤–∏—â–µ–Ω–Ω—è –ª—ñ–º—ñ—Ç—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è ("–¢–∞–∫" –∞–±–æ "–ù—ñ").

    Returns:
        pd.DataFrame: DataFrame, –≥–æ—Ç–æ–≤–∏–π –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü—ñ—ó —Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è.
    """
    data = {
        "is_tv_subscriber": 1 if is_tv == "–¢–∞–∫" else 0,
        "is_movie_package_subscriber": 1 if is_movie == "–¢–∞–∫" else 0,
        "download_over_limit": 1 if over_limit == "–¢–∞–∫" else 0,
        "subscription_age": sub_age,
        "bill_avg": bill,
        "reamining_contract": contract,
        "service_failure_count": failures,
        "download_avg": down,
        "upload_avg": up,
    }
    return pd.DataFrame([data])


def get_risk_category(probability: float) -> Tuple[str, str, str]:
    """
    –í–∏–∑–Ω–∞—á–∞—î –∫–∞—Ç–µ–≥–æ—Ä—ñ—é —Ä–∏–∑–∏–∫—É –≤—ñ–¥—Ç–æ–∫—É –∫–ª—ñ—î–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ.

    Args:
        probability (float): –ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –≤—ñ–¥—Ç–æ–∫—É –∫–ª—ñ—î–Ω—Ç–∞ (–∑–Ω–∞—á–µ–Ω–Ω—è –≤—ñ–¥ 0 –¥–æ 1).

    Returns:
        Tuple[str, str, str]: –ö–æ—Ä—Ç–µ–∂, —â–æ –º—ñ—Å—Ç–∏—Ç—å:
                                1. –ú—ñ—Ç–∫—É —Ä–∏–∑–∏–∫—É (–Ω–∞–ø—Ä., "–í–∏—Å–æ–∫–∏–π —Ä–∏–∑–∏–∫").
                                2. –¢–∏–ø —Å—Ç–∞–Ω—É Streamlit (–Ω–∞–ø—Ä., "error").
                                3. –ö–æ–ª—ñ—Ä (HEX, –Ω–∞–ø—Ä., "#dc3545").
    """
    if probability >= 0.7:
        return "üî¥ –í–∏—Å–æ–∫–∏–π —Ä–∏–∑–∏–∫", "error", "#dc3545"
    elif probability >= 0.4:
        return "üü° –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–∏–∑–∏–∫", "warning", "#ffc107"
    else:
        return "üü¢ –ù–∏–∑—å–∫–∏–π —Ä–∏–∑–∏–∫", "success", "#86AC41"


def generate_recommendations(input_data: dict, probability: float) -> list:
    """
    –ì–µ–Ω–µ—Ä—É—î –ø–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó —â–æ–¥–æ —É—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–ª—ñ—î–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤—ñ
    –π–æ–≥–æ –≤—Ö—ñ–¥–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ —Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–æ—ó –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ –≤—ñ–¥—Ç–æ–∫—É.

    Args:
        input_data (Dict[str, Any]): –°–ª–æ–≤–Ω–∏–∫ –∑ –∫–ª—é—á–æ–≤–∏–º–∏ –æ–∑–Ω–∞–∫–∞–º–∏ –∫–ª—ñ—î–Ω—Ç–∞.
        probability (float): –ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –≤—ñ–¥—Ç–æ–∫—É.

    Returns:
        List[str]: –°–ø–∏—Å–æ–∫ —Ä—è–¥–∫—ñ–≤ –∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è–º–∏.
    """
    recommendations = []

    if input_data["reamining_contract"] < 0.5:
        recommendations.append(
            "‚ö†Ô∏è **–¢–µ—Ä–º—ñ–Ω–æ–≤–∞ –¥—ñ—è:** –ö–æ–Ω—Ç—Ä–∞–∫—Ç –∑–∞–∫—ñ–Ω—á—É—î—Ç—å—Å—è. –ó–∞–ø—Ä–æ–ø–æ–Ω—É–π—Ç–µ –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è."
        )

    if input_data["service_failure_count"] > 3:
        recommendations.append(
            "üîß **–¢–µ—Ö–Ω—ñ—á–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞:** –í–∏—Å–æ–∫–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–±–æ—ó–≤. –ü–æ—Ç—Ä—ñ–±–Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—è."
        )

    if input_data["bill_avg"] > 100 and probability > 0.5:
        recommendations.append(
            "üí∞ **–§—ñ–Ω–∞–Ω—Å–æ–≤–∞ –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—è:** –ö–ª—ñ—î–Ω—Ç –∑ –≤–∏—Å–æ–∫–∏–º —á–µ–∫–æ–º –ø—ñ–¥ —Ä–∏–∑–∏–∫–æ–º. –†–æ–∑–≥–ª—è–Ω—å—Ç–µ –∑–Ω–∏–∂–∫—É."
        )

    if input_data["download_over_limit"] == 1:
        recommendations.append(
            "üìä **–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —Ç–∞—Ä–∏—Ñ—É:** –ü–µ—Ä–µ–≤–∏—â–µ–Ω–Ω—è –ª—ñ–º—ñ—Ç—É. –ó–∞–ø—Ä–æ–ø–æ–Ω—É–π—Ç–µ –±—ñ–ª—å—à–∏–π —Ç–∞—Ä–∏—Ñ."
        )

    if (
        not input_data["is_tv_subscriber"]
        and not input_data["is_movie_package_subscriber"]
    ):
        recommendations.append(
            "üì∫ **–î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø–æ—Å–ª—É–≥–∏:** –ó–∞–ø—Ä–æ–ø–æ–Ω—É–π—Ç–µ –ø—Ä–æ–±–Ω–∏–π –ø–µ—Ä—ñ–æ–¥ –¢–í –∞–±–æ –∫—ñ–Ω–æ–ø–∞–∫–µ—Ç—É."
        )

    if len(recommendations) == 0:
        recommendations.append(
            "‚úÖ –ö–ª—ñ—î–Ω—Ç –º–∞—î —Å—Ç–∞–±—ñ–ª—å–Ω–∏–π –ø—Ä–æ—Ñ—ñ–ª—å. –ü—ñ–¥—Ç—Ä–∏–º—É–π—Ç–µ —è–∫—ñ—Å—Ç—å –æ–±—Å–ª—É–≥–æ–≤—É–≤–∞–Ω–Ω—è."
        )

    return recommendations


# ---------------------------------------------------------------
# 6. –°–¢–û–†–Ü–ù–ö–ê 1: –†—É—á–Ω–µ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
# ---------------------------------------------------------------
def manual_input_page(model, scaler):
    """
    –í—ñ–¥–æ–±—Ä–∞–∂–∞—î —Å—Ç–æ—Ä—ñ–Ω–∫—É –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–µ–¥–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∫–ª—ñ—î–Ω—Ç–∞, –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
    –ø—Ä–æ–≥–Ω–æ–∑—É –≤—ñ–¥—Ç–æ–∫—É —Ç–∞ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π.

    Args:
        model (Any): –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å ML.
        scaler (Any): –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–π —Å–∫–µ–π–ª–µ—Ä –¥–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö.
    """
    st.markdown("## üéØ –Ü–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏–π –ü—Ä–æ–≥–Ω–æ–∑ –í—ñ–¥—Ç–æ–∫—É")
    st.markdown("---")

    if not MODEL_LOADED:
        st.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞.")
        return

    with st.expander("‚ÑπÔ∏è –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è"):
        st.markdown(
            """
        1. –ó–∞–ø–æ–≤–Ω—ñ—Ç—å –ø–æ–ª—è –∑ –¥–∞–Ω–∏–º–∏ –∫–ª—ñ—î–Ω—Ç–∞
        2. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å "–ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞—Ç–∏"
        3. –û—Ç—Ä–∏–º–∞–π—Ç–µ –∞–Ω–∞–ª—ñ–∑ —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        """
        )

    st.subheader("üîß –í–≤–µ–¥—ñ—Ç—å –¥–∞–Ω—ñ –∫–ª—ñ—î–Ω—Ç–∞")
    col1, col2 = st.columns(2)

    with col1:
        is_tv = st.selectbox("üì∫ –ü—ñ–¥–ø–∏—Å–∫–∞ –Ω–∞ –¢–ë", ["–¢–∞–∫", "–ù—ñ"])
        is_movie = st.selectbox("üé¨ –ü–∞–∫–µ—Ç —Ñ—ñ–ª—å–º—ñ–≤", ["–¢–∞–∫", "–ù—ñ"])
        sub_age = st.number_input(
            "‚è±Ô∏è –¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –ø—ñ–¥–ø–∏—Å–∫–∏ (—Ä–æ–∫—ñ–≤)",
            0.0,
            20.0,
            2.0,
            0.1,
            help=FIELD_TOOLTIPS["subscription_age"],
        )
        bill = st.number_input(
            "üíµ –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–∞—Ö—É–Ω–æ–∫ ($)",
            0.0,
            500.0,
            25.0,
            1.0,
            help=FIELD_TOOLTIPS["bill_avg"],
        )

    with col2:
        contract = st.number_input(
            "üìã –ó–∞–ª–∏—à–æ–∫ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É (—Ä–æ–∫—ñ–≤)",
            0.0,
            10.0,
            1.0,
            0.1,
            help=FIELD_TOOLTIPS["reamining_contract"],
        )
        failures = st.number_input(
            "‚ö†Ô∏è –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–±–æ—ó–≤ —Å–µ—Ä–≤—ñ—Å—É",
            0,
            20,
            0,
            help=FIELD_TOOLTIPS["service_failure_count"],
        )
        down = st.number_input(
            "‚¨áÔ∏è –°–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (GB)",
            0.0,
            5000.0,
            50.0,
            help=FIELD_TOOLTIPS["download_avg"],
        )
        up = st.number_input(
            "‚¨ÜÔ∏è –°–µ—Ä–µ–¥–Ω—î –≤—ñ–¥–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (GB)",
            0.0,
            500.0,
            5.0,
            help=FIELD_TOOLTIPS["upload_avg"],
        )
        over_limit = st.selectbox("üö´ –ü–µ—Ä–µ–≤–∏—â–µ–Ω–Ω—è –ª—ñ–º—ñ—Ç—É", ["–¢–∞–∫", "–ù—ñ"])

    if st.button("üîÆ –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞—Ç–∏"):
        progress_bar = st.progress(0)
        status = st.empty()

        status.text("‚è≥ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞...")
        progress_bar.progress(25)
        time.sleep(0.3)

        input_df = prepare_input_data(
            is_tv, is_movie, sub_age, bill, contract, failures, down, up, over_limit
        )

        status.text("üîÑ –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è...")
        progress_bar.progress(50)
        time.sleep(0.3)

        try:
            input_df_aligned = align_features(input_df, scaler)
            X_scaled = scaler.transform(input_df_aligned)
            prediction = model.predict(X_scaled)[0]
            probability = model.predict_proba(X_scaled)[0][1]

            progress_bar.progress(100)
            time.sleep(0.2)
            status.empty()
            progress_bar.empty()

        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            return

        st.markdown("---")
        st.subheader("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑—É")

        risk_label, risk_type, risk_color = get_risk_category(probability)

        col1, col2, col3 = st.columns(3)
        col1.metric("–°—Ç–∞—Ç—É—Å", "–í—ñ–¥—Ç—ñ–∫ ‚ùå" if prediction == 1 else "–ó–∞–ª–∏—à–∏—Ç—å—Å—è ‚úÖ")
        col2.metric("–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –≤—ñ–¥—Ç–æ–∫—É", f"{probability:.1%}")
        col3.markdown(f"### {risk_label}")

        fig, ax = plt.subplots(figsize=(10, 6))
        probs = [1 - probability, probability]
        labels = ["–ó–∞–ª–∏—à–∏—Ç—å—Å—è", "–í—ñ–¥—Ç—ñ–∫"]
        colors = ["#86AC41", "#dc3545"]

        bars = ax.bar(
            labels, probs, color=colors, edgecolor="#324851", linewidth=2, width=0.6
        )
        ax.set_ylim(0, 1.1)
        ax.set_ylabel("–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å", fontsize=13, fontweight="bold")
        ax.set_title(
            "–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –í—ñ–¥—Ç–æ–∫—É / –£—Ç—Ä–∏–º–∞–Ω–Ω—è", fontsize=15, fontweight="bold", pad=20
        )
        ax.spines["top"].set_visible(False)
        ax.spines["right"].set_visible(False)
        ax.grid(axis="y", alpha=0.3)

        for prob, bar in zip(probs, bars):
            ax.text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.03,
                f"{prob:.1%}",
                ha="center",
                fontweight="bold",
                fontsize=13,
            )

        plt.tight_layout()
        st.pyplot(fig)

        st.markdown("---")
        st.subheader("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó")

        input_dict = {
            "is_tv_subscriber": 1 if is_tv == "–¢–∞–∫" else 0,
            "is_movie_package_subscriber": 1 if is_movie == "–¢–∞–∫" else 0,
            "subscription_age": sub_age,
            "bill_avg": bill,
            "reamining_contract": contract,
            "service_failure_count": failures,
            "download_avg": down,
            "upload_avg": up,
            "download_over_limit": 1 if over_limit == "–¢–∞–∫" else 0,
        }

        for i, rec in enumerate(generate_recommendations(input_dict, probability), 1):
            st.info(f"**{i}.** {rec}")


# ---------------------------------------------------------------
# 7. –°–¢–û–†–Ü–ù–ö–ê 2: –ü–∞–∫–µ—Ç–Ω–µ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
# ---------------------------------------------------------------
def batch_upload_page(model, scaler):
    """
    –í—ñ–¥–æ–±—Ä–∞–∂–∞—î —Å—Ç–æ—Ä—ñ–Ω–∫—É –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è CSV-—Ñ–∞–π–ª—É,
    –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –º–∞—Å–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑—É –≤—ñ–¥—Ç–æ–∫—É —Ç–∞ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–≤–µ–¥–µ–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤.

    Args:
        model (Any): –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å ML.
        scaler (Any): –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–π —Å–∫–µ–π–ª–µ—Ä –¥–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö.
    """
    st.markdown("## üì§ –ü–∞–∫–µ—Ç–Ω–µ –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è")
    st.markdown("---")
    st.info("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ CSV —Ñ–∞–π–ª –¥–ª—è –º–∞—Å–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑—É.")

    if not MODEL_LOADED:
        st.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞.")
        return

    with st.expander("üìã –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —à–∞–±–ª–æ–Ω"):
        template = pd.DataFrame(
            {
                "is_tv_subscriber": [1, 0, 1],
                "is_movie_package_subscriber": [0, 1, 1],
                "subscription_age": [2.5, 5.0, 1.2],
                "bill_avg": [45.0, 78.0, 32.0],
                "reamining_contract": [1.0, 0.5, 2.0],
                "service_failure_count": [2, 5, 1],
                "download_avg": [120.0, 450.0, 80.0],
                "upload_avg": [15.0, 35.0, 10.0],
                "download_over_limit": [0, 1, 0],
            }
        )
        st.download_button(
            "üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏",
            template.to_csv(index=False).encode("utf-8"),
            "template.csv",
            "text/csv",
        )

    uploaded = st.file_uploader("–û–±–µ—Ä—ñ—Ç—å CSV", type="csv")

    if uploaded:
        try:
            data = pd.read_csv(uploaded)
            st.subheader("üìÑ –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø–µ—Ä–µ–≥–ª—è–¥")
            st.dataframe(data.head(10), use_container_width=True)

            if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–∏"):
                progress = st.progress(0)
                status = st.empty()

                status.text("‚è≥ –û–±—Ä–æ–±–∫–∞...")
                progress.progress(30)
                time.sleep(0.3)

                try:
                    data_prep = align_features(data.copy(), scaler)
                    status.text("üîÑ –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è...")
                    progress.progress(60)

                    X_scaled = scaler.transform(data_prep)
                    data["Prediction"] = model.predict(X_scaled)
                    data["Probability"] = model.predict_proba(X_scaled)[:, 1]

                    progress.progress(100)
                    time.sleep(0.2)
                    status.empty()
                    progress.empty()

                except Exception as e:
                    st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
                    return

                data["–°—Ç–∞—Ç—É—Å"] = data["Prediction"].map({1: "–í—ñ–¥—Ç—ñ–∫", 0: "–ó–∞–ª–∏—à–∏—Ç—å—Å—è"})
                data["–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å"] = data["Probability"].apply(lambda x: f"{x:.2%}")
                data["–†–∏–∑–∏–∫"] = data["Probability"].apply(
                    lambda x: get_risk_category(x)[0]
                )

                st.subheader("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏")
                st.dataframe(
                    data.drop(columns=["Prediction", "Probability"], errors="ignore"),
                    use_container_width=True,
                )

                col1, col2, col3, col4 = st.columns(4)
                col1.metric("üìä –í—Å—å–æ–≥–æ", len(data))
                col2.metric("üìâ –í—ñ–¥—Ç—ñ–∫", sum(data["Prediction"] == 1))
                col3.metric("üìà –£—Ç—Ä–∏–º–∞–Ω–Ω—è", sum(data["Prediction"] == 0))
                col4.metric("üî¥ –í–∏—Å–æ–∫–∏–π —Ä–∏–∑–∏–∫", sum(data["Probability"] >= 0.7))

                st.markdown("---")
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.hist(
                    data["Probability"],
                    bins=20,
                    color="#86AC41",
                    edgecolor="#324851",
                    alpha=0.7,
                )
                ax.axvline(
                    0.5, color="#dc3545", linestyle="--", linewidth=2, label="–ü–æ—Ä—ñ–≥"
                )
                ax.set_xlabel("–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –≤—ñ–¥—Ç–æ–∫—É", fontsize=12, fontweight="bold")
                ax.set_ylabel("–ö—ñ–ª—å–∫—ñ—Å—Ç—å", fontsize=12, fontweight="bold")
                ax.set_title("–†–æ–∑–ø–æ–¥—ñ–ª –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π", fontsize=14, fontweight="bold")
                ax.legend()
                st.pyplot(fig)

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    "üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏",
                    data.to_csv(index=False).encode("utf-8"),
                    f"predictions_{timestamp}.csv",
                    "text/csv",
                )

        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è: {e}")


# ---------------------------------------------------------------
# 8. –°–¢–û–†–Ü–ù–ö–ê 3: –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞
# ---------------------------------------------------------------
def data_analysis_page():
    """
    –í—ñ–¥–æ–±—Ä–∞–∂–∞—î —Å—Ç–æ—Ä—ñ–Ω–∫—É –∞–Ω–∞–ª—ñ–∑—É –¥–∞–Ω–∏—Ö, –∑–æ–∫—Ä–µ–º–∞, –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫
    –¥–ª—è –º–æ–¥–µ–ª—ñ (Feature Importance).
    """
    st.markdown("## üîé –ê–Ω–∞–ª—ñ–∑ –§–∞–∫—Ç–æ—Ä—ñ–≤ –í—ñ–¥—Ç–æ–∫—É")
    st.markdown("---")

    st.subheader("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó")
    st.warning(
        "–°—Ñ–æ–∫—É—Å—É–π—Ç–µ—Å—è –Ω–∞ –∫–ª—ñ—î–Ω—Ç–∞—Ö –∑ –≤–∏—Å–æ–∫–æ—é –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—é –≤—ñ–¥—Ç–æ–∫—É: –ø—Ä–æ–ø–æ–Ω—É–π—Ç–µ –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É —Ç–∞ –º—ñ–Ω—ñ–º—ñ–∑—É–π—Ç–µ –∑–±–æ—ó."
    )

    if hasattr(model, "feature_importances_"):
        try:
            fi = pd.Series(
                model.feature_importances_,
                index=getattr(
                    scaler, "feature_names_in_", range(len(model.feature_importances_))
                ),
            )
            fi = fi.sort_values(ascending=False)
            fi_df = fi.reset_index()
            fi_df.columns = ["–û–∑–Ω–∞–∫–∞", "–í–∞–∂–ª–∏–≤—ñ—Å—Ç—å"]
            fi_df["–û–∑–Ω–∞–∫–∞"] = fi_df["–û–∑–Ω–∞–∫–∞"].replace(FEATURE_NAMES_MAP)
        except:
            fi_df = pd.DataFrame(
                {
                    "–û–∑–Ω–∞–∫–∞": list(FEATURE_NAMES_MAP.values()),
                    "–í–∞–∂–ª–∏–≤—ñ—Å—Ç—å": np.linspace(0.35, 0.01, len(FEATURE_NAMES_MAP)),
                }
            )
    else:
        fi_df = pd.DataFrame(
            {
                "–û–∑–Ω–∞–∫–∞": list(FEATURE_NAMES_MAP.values()),
                "–í–∞–∂–ª–∏–≤—ñ—Å—Ç—å": np.linspace(0.35, 0.01, len(FEATURE_NAMES_MAP)),
            }
        )

    fi_df = fi_df[~fi_df["–û–∑–Ω–∞–∫–∞"].str.contains("_missing", case=False, na=False)]

    fig, ax = plt.subplots(figsize=(10, 7))
    colors = plt.cm.coolwarm(np.linspace(0, 1, len(fi_df)))
    bars = ax.barh(
        fi_df["–û–∑–Ω–∞–∫–∞"],
        fi_df["–í–∞–∂–ª–∏–≤—ñ—Å—Ç—å"],
        color=colors,
        edgecolor="#324851",
        linewidth=1.5,
    )
    ax.set_xlabel("–í–∞–∂–ª–∏–≤—ñ—Å—Ç—å", fontsize=12, fontweight="bold")
    ax.set_ylabel("–û–∑–Ω–∞–∫–∞", fontsize=12, fontweight="bold")
    ax.set_title("–ö–ª—é—á–æ–≤—ñ —Ñ–∞–∫—Ç–æ—Ä–∏ –≤—ñ–¥—Ç–æ–∫—É", fontsize=14, fontweight="bold", pad=20)
    ax.invert_yaxis()

    for bar in bars:
        ax.text(
            bar.get_width() + 0.02,
            bar.get_y() + bar.get_height() / 2,
            f"{bar.get_width():.2f}",
            va="center",
            fontsize=10,
        )

    plt.tight_layout()
    st.pyplot(fig)


# ---------------------------------------------------------------
# 9. –°–¢–û–†–Ü–ù–ö–ê 4: –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ
# ---------------------------------------------------------------
def model_performance_page():
    """
    –í—ñ–¥–æ–±—Ä–∞–∂–∞—î —Å—Ç–æ—Ä—ñ–Ω–∫—É –∑ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è–º –º–µ—Ç—Ä–∏–∫ —Ä—ñ–∑–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π ML,
    –≤–∫–ª—é—á–∞—é—á–∏ —Ç–∞–±–ª–∏—Ü—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤, –¥—ñ–∞–≥—Ä–∞–º–∏ "—Ç–æ—á–Ω—ñ—Å—Ç—å vs —à–≤–∏–¥–∫—ñ—Å—Ç—å",
    —Ä–∞–¥–∞—Ä–Ω—É –¥—ñ–∞–≥—Ä–∞–º—É —Ç–∞ —Ç–µ–ø–ª–æ–≤—É –∫–∞—Ä—Ç—É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º–µ—Ç—Ä–∏–∫.
    """
    st.markdown("## üìà –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ú–æ–¥–µ–ª–µ–π ML")
    st.markdown("---")

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
    results_path = "models/models_comparison_summary.csv"
    df = None

    if os.path.exists(results_path):
        try:
            df = pd.read_csv(results_path)
            st.success("‚úÖ –î–∞–Ω—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑ —Ñ–∞–π–ª—É")

            # –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–∏—Ö –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            with st.expander("üîç –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–∏—Ö"):
                st.write("**–°—Ç–æ–≤–ø—Ü—ñ:**", list(df.columns))
                st.dataframe(df.head(3))

        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è —Ñ–∞–π–ª—É: {e}")
            df = None

    # –Ø–∫—â–æ —Ñ–∞–π–ª –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏–≤—Å—è, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –¥–µ–º–æ-–¥–∞–Ω—ñ
    if df is None:
        st.warning("‚ö†Ô∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ–π–Ω—ñ –¥–∞–Ω—ñ")
        df = pd.DataFrame(
            {
                "model": [
                    "LightGBM",
                    "RandomForest",
                    "CatBoost",
                    "GradientBoosting",
                    "MLP",
                    "SVC_linear",
                    "LogisticRegression",
                ],
                "train_time_s": [1.25, 16.11, 38.67, 14.46, 3348.95, 1201.85, 0.13],
                "accuracy": [0.947, 0.943, 0.944, 0.940, 0.937, 0.881, 0.878],
                "precision": [0.962, 0.960, 0.961, 0.960, 0.956, 0.876, 0.878],
                "recall": [0.942, 0.937, 0.937, 0.930, 0.930, 0.917, 0.907],
                "f1": [0.952, 0.948, 0.949, 0.945, 0.943, 0.896, 0.892],
                "roc_auc": [0.983, 0.982, 0.982, 0.974, 0.974, 0.936, 0.934],
            }
        )

    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–∞–∑–≤ —Å—Ç–æ–≤–ø—Ü—ñ–≤ (–≤–∏–¥–∞–ª—è—î–º–æ –ø—Ä–æ–±—ñ–ª–∏, –ø–µ—Ä–µ–≤–æ–¥–∏–º–æ –≤ lowercase)
    df.columns = (
        df.columns.str.strip().str.lower().str.replace(" ", "_").str.replace("-", "_")
    )

    # –ú–∞–ø—ñ–Ω–≥ –º–æ–∂–ª–∏–≤–∏—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –Ω–∞–∑–≤ —Å—Ç–æ–≤–ø—Ü—ñ–≤
    column_mapping = {
        "train_time_s": ["train_time_s", "traintime", "training_time", "time"],
        "accuracy": ["accuracy", "acc"],
        "precision": ["precision", "prec"],
        "recall": ["recall", "rec"],
        "f1": ["f1", "f1_score", "f1score"],
        "roc_auc": ["roc_auc", "rocauc", "auc", "roc"],
    }

    # –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –ø–æ—à—É–∫—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ—ó –Ω–∞–∑–≤–∏ —Å—Ç–æ–≤–ø—Ü—è
    def find_column(standard_name, alternatives):
        for alt in alternatives:
            if alt in df.columns:
                return alt
        return None

    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ —Å—Ç–æ–≤–ø—Ü—ñ
    col_map = {}
    for standard, alternatives in column_mapping.items():
        found = find_column(standard, alternatives)
        if found:
            col_map[standard] = found
        else:
            st.warning(
                f"‚ö†Ô∏è –°—Ç–æ–≤–ø–µ—Ü—å '{standard}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ì—Ä–∞—Ñ—ñ–∫–∏ –º–æ–∂—É—Ç—å –±—É—Ç–∏ –Ω–µ–ø–æ–≤–Ω–∏–º–∏."
            )

    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö —Å—Ç–æ–≤–ø—Ü—ñ–≤
    required_cols = ["accuracy", "precision", "recall", "f1", "roc_auc"]
    missing_cols = [col for col in required_cols if col not in col_map]

    if missing_cols:
        st.error(f"‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ —Å—Ç–æ–≤–ø—Ü—ñ: {missing_cols}")
        st.info(
            "üí° –û—á—ñ–∫—É–≤–∞–Ω—ñ –Ω–∞–∑–≤–∏ —Å—Ç–æ–≤–ø—Ü—ñ–≤: model, accuracy, precision, recall, f1, roc_auc, train_time_s (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)"
        )
        return

    st.subheader("üìä –ó–∞–≥–∞–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
    st.dataframe(df, use_container_width=True)

    # –ì–†–ê–§–Ü–ö 1: Scatter plot - –¢–æ—á–Ω—ñ—Å—Ç—å vs –®–≤–∏–¥–∫—ñ—Å—Ç—å (—è–∫—â–æ —î train_time)
    if "train_time_s" in col_map:
        st.markdown("---")
        st.subheader("‚ö° –ë–∞–ª–∞–Ω—Å –º—ñ–∂ –¢–æ—á–Ω—ñ—Å—Ç—é —Ç–∞ –®–≤–∏–¥–∫—ñ—Å—Ç—é –ù–∞–≤—á–∞–Ω–Ω—è")

        fig1, ax1 = plt.subplots(figsize=(12, 7))

        time_col = col_map["train_time_s"]
        acc_col = col_map["accuracy"]
        f1_col = col_map["f1"]
        roc_col = col_map["roc_auc"]

        scatter = ax1.scatter(
            df[time_col],
            df[acc_col],
            s=df[f1_col] * 500,
            c=df[roc_col],
            cmap="RdYlGn",
            alpha=0.7,
            edgecolors="#324851",
            linewidth=2,
        )

        ax1.set_xscale("log")
        ax1.set_xlabel(
            "–ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è (—Å–µ–∫—É–Ω–¥–∏, –ª–æ–≥-—à–∫–∞–ª–∞)", fontsize=13, fontweight="bold"
        )
        ax1.set_ylabel("Accuracy", fontsize=13, fontweight="bold")
        ax1.set_title(
            "–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π: –¢–æ—á–Ω—ñ—Å—Ç—å vs –®–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è",
            fontsize=15,
            fontweight="bold",
            pad=20,
        )
        ax1.grid(True, alpha=0.3)

        # –î–æ–¥–∞—î–º–æ –Ω–∞–∑–≤–∏ –º–æ–¥–µ–ª–µ–π
        model_col = "model" if "model" in df.columns else df.columns[0]
        for i, model in enumerate(df[model_col]):
            ax1.annotate(
                model,
                (df[time_col].iloc[i], df[acc_col].iloc[i]),
                xytext=(5, 5),
                textcoords="offset points",
                fontsize=9,
                fontweight="bold",
            )

        cbar = plt.colorbar(scatter, ax=ax1)
        cbar.set_label("ROC AUC", fontsize=11, fontweight="bold")

        plt.tight_layout()
        st.pyplot(fig1)

        st.info(
            "üí° **–†–æ–∑–º—ñ—Ä —Ç–æ—á–æ–∫** –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î F1-score. **–ö–æ–ª—ñ—Ä** –ø–æ–∫–∞–∑—É—î ROC AUC (–∑–µ–ª–µ–Ω–∏–π = –∫—Ä–∞—â–∏–π)."
        )
    else:
        st.info(
            "‚ÑπÔ∏è –ì—Ä–∞—Ñ—ñ–∫ '–¢–æ—á–Ω—ñ—Å—Ç—å vs –®–≤–∏–¥–∫—ñ—Å—Ç—å' –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π (–≤—ñ–¥—Å—É—Ç–Ω—ñ –¥–∞–Ω—ñ –ø—Ä–æ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è)"
        )

    # –ì–†–ê–§–Ü–ö 2: Radar Chart - –ë–∞–≥–∞—Ç–æ–≤–∏–º—ñ—Ä–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ç–æ–ø-3 –º–æ–¥–µ–ª–µ–π
    st.markdown("---")
    st.subheader("üéØ –ë–∞–≥–∞—Ç–æ–≤–∏–º—ñ—Ä–Ω–µ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –¢–æ–ø-3 –ú–æ–¥–µ–ª–µ–π")

    # –í—ñ–¥–±–∏—Ä–∞—î–º–æ —Ç–æ–ø-3 –∑–∞ F1
    f1_col = col_map["f1"]
    top3 = df.nlargest(3, f1_col)

    categories = ["Accuracy", "Precision", "Recall", "F1", "ROC AUC"]

    fig2, ax2 = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection="polar"))

    angles = [n / float(len(categories)) * 2 * pi for n in range(len(categories))]
    angles += angles[:1]

    colors_radar = ["#86AC41", "#34675C", "#7DA3A1"]

    model_col = "model" if "model" in df.columns else df.columns[0]

    for idx, (i, row) in enumerate(top3.iterrows()):
        values = [
            row[col_map["accuracy"]],
            row[col_map["precision"]],
            row[col_map["recall"]],
            row[col_map["f1"]],
            row[col_map["roc_auc"]],
        ]
        values += values[:1]

        ax2.plot(
            angles,
            values,
            "o-",
            linewidth=2,
            label=row[model_col],
            color=colors_radar[idx],
        )
        ax2.fill(angles, values, alpha=0.15, color=colors_radar[idx])

    ax2.set_xticks(angles[:-1])
    ax2.set_xticklabels(categories, fontsize=11, fontweight="bold")
    ax2.set_ylim(0.85, 1.0)
    ax2.set_title(
        "–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ –Ω–∞–π–∫—Ä–∞—â–∏—Ö –º–æ–¥–µ–ª–µ–π", fontsize=15, fontweight="bold", pad=30
    )
    ax2.legend(loc="upper right", bbox_to_anchor=(1.3, 1.1), fontsize=11)
    ax2.grid(True)

    plt.tight_layout()
    st.pyplot(fig2)

    # –ì–†–ê–§–Ü–ö 3: Heatmap –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º–µ—Ç—Ä–∏–∫
    st.markdown("---")
    st.subheader("üî• –ö–æ—Ä–µ–ª—è—Ü—ñ—è –º—ñ–∂ –ú–µ—Ç—Ä–∏–∫–∞–º–∏")

    metrics_cols = [
        col_map[key] for key in ["accuracy", "precision", "recall", "f1", "roc_auc"]
    ]
    metrics_df = df[metrics_cols]

    # –ü–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î–º–æ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    metrics_df.columns = ["Accuracy", "Precision", "Recall", "F1", "ROC AUC"]
    corr = metrics_df.corr()

    fig3, ax3 = plt.subplots(figsize=(10, 8))
    sns.heatmap(
        corr,
        annot=True,
        fmt=".2f",
        cmap="coolwarm",
        center=0,
        square=True,
        linewidths=1,
        cbar_kws={"shrink": 0.8},
        ax=ax3,
        vmin=-1,
        vmax=1,
    )
    ax3.set_title(
        "–ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º–µ—Ç—Ä–∏–∫ —è–∫–æ—Å—Ç—ñ", fontsize=15, fontweight="bold", pad=20
    )

    plt.tight_layout()
    st.pyplot(fig3)

    st.info(
        "üí° –°–∏–ª—å–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è –º—ñ–∂ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –≤–∫–∞–∑—É—î –Ω–∞ —É–∑–≥–æ–¥–∂–µ–Ω—ñ—Å—Ç—å –æ—Ü—ñ–Ω–∫–∏ —è–∫–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π."
    )

    # –í–∏—Å–Ω–æ–≤–æ–∫
    st.markdown("---")
    st.subheader("üìä –í–∏—Å–Ω–æ–≤–∫–∏")

    f1_col = col_map["f1"]
    model_col = "model" if "model" in df.columns else df.columns[0]

    best_model = df.loc[df[f1_col].idxmax()]

    col1, col2 = st.columns(2)

    with col1:
        st.success(
            f"""
        **üèÜ –ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å –∑–∞ —è–∫—ñ—Å—Ç—é:**
        **{best_model[model_col]}**
        - F1-Score: {best_model[f1_col]:.3f}
        - ROC AUC: {best_model[col_map['roc_auc']]:.3f}
        - Accuracy: {best_model[col_map['accuracy']]:.3f}
        """
        )

    with col2:
        if "train_time_s" in col_map:
            time_col = col_map["train_time_s"]
            fastest_model = df.loc[df[time_col].idxmin()]
            st.info(
                f"""
            **‚ö° –ù–∞–π—à–≤–∏–¥—à–∞ –º–æ–¥–µ–ª—å:**
            **{fastest_model[model_col]}**
            - –ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: {fastest_model[time_col]:.2f}s
            - F1-Score: {fastest_model[f1_col]:.3f}
            - ROC AUC: {fastest_model[col_map['roc_auc']]:.3f}
            """
            )
        else:
            st.info(
                """
            **‚ÑπÔ∏è –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ —à–≤–∏–¥–∫—ñ—Å—Ç—å:**
            –î–∞–Ω—ñ –ø—Ä–æ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è –≤—ñ–¥—Å—É—Ç–Ω—ñ —É —Ñ–∞–π–ª—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤.
            """
            )

    # –î–æ–¥–∞—Ç–∫–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    st.markdown("---")
    st.subheader("üìà –ó–∞–≥–∞–ª—å–Ω–∞ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)

    col_stat1.metric(
        "–°–µ—Ä–µ–¥–Ω—ñ–π F1-Score", f"{df[f1_col].mean():.3f}", f"¬±{df[f1_col].std():.3f}"
    )

    col_stat2.metric(
        "–°–µ—Ä–µ–¥–Ω—ñ–π ROC AUC",
        f"{df[col_map['roc_auc']].mean():.3f}",
        f"¬±{df[col_map['roc_auc']].std():.3f}",
    )

    col_stat3.metric("–ö—ñ–ª—å–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª–µ–π", len(df))

    col_stat4.metric(
        "–ù–∞–π–∫—Ä–∞—â–∞ –º–µ—Ç—Ä–∏–∫–∞",
        f"{df[f1_col].max():.3f}",
        f"+{(df[f1_col].max() - df[f1_col].min()):.3f}",
    )


# =====================================================================
# 10. –ì–û–õ–û–í–ù–ê –ù–ê–í–Ü–ì–ê–¶–Ü–Ø
# =====================================================================
if __name__ == "__main__":
    # –ó–ê–ì–ê–õ–¨–ù–ò–ô –ó–ê–ì–û–õ–û–í–û–ö –î–õ–Ø –í–°–Ü–• –í–ö–õ–ê–î–û–ö
    st.sidebar.markdown("# üìä –ü—Ä–æ–≥–Ω–æ–∑ –í—ñ–¥—Ç–æ–∫—É")
    st.sidebar.markdown(
        "### –ê–Ω–∞–ª—ñ—Ç–∏—á–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –ø–æ–≤–µ–¥—ñ–Ω–∫–∏ –∫–ª—ñ—î–Ω—Ç—ñ–≤ —Ç–µ–ª–µ–∫–æ–º-–∫–æ–º–ø–∞–Ω—ñ—ó"
    )
    st.sidebar.markdown("---")

    # –ú–µ–Ω—é –Ω–∞–≤—ñ–≥–∞—Ü—ñ—ó
    st.sidebar.title("üß≠ –ú–µ–Ω—é")
    main_menu = st.sidebar.radio(
        "–û–±–µ—Ä—ñ—Ç—å —Ä–æ–∑–¥—ñ–ª",
        ["–†—É—á–Ω–∏–π –≤–≤—ñ–¥", "–ü–∞–∫–µ—Ç–Ω–∏–π –≤–≤—ñ–¥", "–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–∞ –ó–≤—ñ—Ç–∏"],
        index=0,
    )

    # –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü—ñ—è
    if main_menu == "–†—É—á–Ω–∏–π –≤–≤—ñ–¥":
        manual_input_page(model, scaler)

    elif main_menu == "–ü–∞–∫–µ—Ç–Ω–∏–π –≤–≤—ñ–¥":
        batch_upload_page(model, scaler)

    else:
        st.markdown("## üìà –ê–Ω–∞–ª—ñ—Ç–∏—á–Ω–∏–π –ü–æ—Ä—Ç–∞–ª")
        st.caption("–í–∏–±–µ—Ä—ñ—Ç—å —Ç–∏–ø –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ–≥–ª—è–¥—É")
        st.markdown("---")

        analytic_tab = st.selectbox(
            "–í–∏–±–µ—Ä—ñ—Ç—å —Ç–∏–ø –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏",
            ["–û–≥–ª—è–¥ –î–∞–Ω–∏—Ö —Ç–∞ –§–∞–∫—Ç–æ—Ä—ñ–≤ –í—ñ–¥—Ç–æ–∫—É", "–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ú–æ–¥–µ–ª–µ–π ML"],
        )

        if analytic_tab == "–û–≥–ª—è–¥ –î–∞–Ω–∏—Ö —Ç–∞ –§–∞–∫—Ç–æ—Ä—ñ–≤ –í—ñ–¥—Ç–æ–∫—É":
            data_analysis_page()
        elif analytic_tab == "–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ú–æ–¥–µ–ª–µ–π ML":
            model_performance_page()

    # –§—É—Ç–µ—Ä
    st.sidebar.markdown("---")
    st.sidebar.caption("¬© 2025 Predictive Minds Lab üì°")
    st.sidebar.caption("–í–µ—Ä—Å—ñ—è: 1.0")

    # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–¥–µ–ª—å
    if MODEL_LOADED:
        st.sidebar.success("üü¢ –ú–æ–¥–µ–ª—å –∞–∫—Ç–∏–≤–Ω–∞")
    else:
        st.sidebar.error("üî¥ –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞")
